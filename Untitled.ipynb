{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51c1be9-ba02-4d02-83f5-a366c532b7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e244e3-fce6-4a34-b88d-a175b053941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from conllu import parse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the CoNLL-U dataset\n",
    "with open('fr_sequoia-ud-train.conllu', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Parse the CoNLL-U data\n",
    "sentences = parse(data)\n",
    "\n",
    "# Accessing different columns and creating lines with morphological features\n",
    "lines = []\n",
    "feats = []\n",
    "for sentence in sentences:\n",
    "    for token in sentence:\n",
    "        if isinstance(token, dict):\n",
    "            word = token['form']\n",
    "            morph_feat = token['feats'] if 'feats' in token else ''\n",
    "            if morph_feat != None :\n",
    "                morph_feat=' | '.join(f\"{key}: {value}\" for key, value in morph_feat.items())\n",
    "                feats.append(morph_feat )\n",
    "            else :\n",
    "                feats.append(\"None\")\n",
    "            lines.append(word)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e63d15-afcf-4552-a6fd-33b496156026",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pairs=[]\n",
    "for feat in feats : \n",
    "    if feat!= 'None' : \n",
    "        feat_pairs.append(feat.split(\"|\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a234bff-b27f-4ad1-8a43-a0f41791247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8670221-525e-49cb-ad82-1acd3ec7aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "feat_pairs=list(chain(*feat_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3840d29a-45e1-4ae9-837a-6a1bb2fbd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes=set(feat_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3648e7-7bde-43b9-a438-26ff6f0708dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_spaces_unique_classes =[j.replace(\" \", \"\").upper() for j in unique_classes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "567e65cf-d2cf-45f4-a9b6-6f2fab85b516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(no_spaces_unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd07eb-c286-41e9-9382-29698e7c65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbeea85-a1ad-4743-96c1-9969d0945cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bc6450-97ae-48be-a746-8aabe28fbdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON:2</th>\n",
       "      <th>NUMTYPE:ORD</th>\n",
       "      <th>POLARITY:NEG</th>\n",
       "      <th>MOOD:CND</th>\n",
       "      <th>NUMBER:PLUR</th>\n",
       "      <th>REFLEX:YES</th>\n",
       "      <th>NUMBER:SING</th>\n",
       "      <th>PERSON:3</th>\n",
       "      <th>VERBFORM:FIN</th>\n",
       "      <th>PRONTYPE:PRS</th>\n",
       "      <th>...</th>\n",
       "      <th>VERBFORM:PART</th>\n",
       "      <th>PERSON:1</th>\n",
       "      <th>VOICE:PASS</th>\n",
       "      <th>PRONTYPE:ART</th>\n",
       "      <th>VERBFORM:INF</th>\n",
       "      <th>TENSE:IMP</th>\n",
       "      <th>GENDER:FEM</th>\n",
       "      <th>DEFINITE:IND</th>\n",
       "      <th>DEFINITE:DEF</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>apprend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Indochine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Affaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>politico-financière</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51877 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PERSON:2  NUMTYPE:ORD  POLARITY:NEG  MOOD:CND  NUMBER:PLUR  REFLEX:YES  \\\n",
       "0           0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "1           0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "2           0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "3           0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "4           0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "...         ...          ...           ...       ...          ...         ...   \n",
       "51872       0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "51873       0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "51874       0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "51875       0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "51876       0.0          0.0           0.0       0.0          0.0         0.0   \n",
       "\n",
       "       NUMBER:SING  PERSON:3  VERBFORM:FIN  PRONTYPE:PRS  ...  VERBFORM:PART  \\\n",
       "0              0.0       0.0           0.0           0.0  ...            0.0   \n",
       "1              0.0       0.0           0.0           0.0  ...            0.0   \n",
       "2              0.0       0.0           0.0           0.0  ...            0.0   \n",
       "3              0.0       0.0           0.0           0.0  ...            0.0   \n",
       "4              0.0       0.0           0.0           0.0  ...            0.0   \n",
       "...            ...       ...           ...           ...  ...            ...   \n",
       "51872          0.0       0.0           0.0           0.0  ...            0.0   \n",
       "51873          0.0       0.0           0.0           0.0  ...            0.0   \n",
       "51874          0.0       0.0           0.0           0.0  ...            0.0   \n",
       "51875          0.0       0.0           0.0           0.0  ...            0.0   \n",
       "51876          0.0       0.0           0.0           0.0  ...            0.0   \n",
       "\n",
       "       PERSON:1  VOICE:PASS  PRONTYPE:ART  VERBFORM:INF  TENSE:IMP  \\\n",
       "0           0.0         0.0           0.0           0.0        0.0   \n",
       "1           0.0         0.0           0.0           0.0        0.0   \n",
       "2           0.0         0.0           0.0           0.0        0.0   \n",
       "3           0.0         0.0           0.0           0.0        0.0   \n",
       "4           0.0         0.0           0.0           0.0        0.0   \n",
       "...         ...         ...           ...           ...        ...   \n",
       "51872       0.0         0.0           0.0           0.0        0.0   \n",
       "51873       0.0         0.0           0.0           0.0        0.0   \n",
       "51874       0.0         0.0           0.0           0.0        0.0   \n",
       "51875       0.0         0.0           0.0           0.0        0.0   \n",
       "51876       0.0         0.0           0.0           0.0        0.0   \n",
       "\n",
       "       GENDER:FEM  DEFINITE:IND  DEFINITE:DEF                 word  \n",
       "0             0.0           0.0           0.0            Gutenberg  \n",
       "1             0.0           0.0           0.0                Cette  \n",
       "2             0.0           0.0           0.0           exposition  \n",
       "3             0.0           0.0           0.0                 nous  \n",
       "4             0.0           0.0           0.0              apprend  \n",
       "...           ...           ...           ...                  ...  \n",
       "51872         0.0           0.0           0.0                   d'  \n",
       "51873         0.0           0.0           0.0            Indochine  \n",
       "51874         0.0           0.0           0.0                    .  \n",
       "51875         0.0           0.0           0.0              Affaire  \n",
       "51876         0.0           0.0           0.0  politico-financière  \n",
       "\n",
       "[51877 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "num_rows = 51877\n",
    "num_columns = 31\n",
    "feat_classes= list(set(no_spaces_unique_classes))\n",
    "df = pd.DataFrame(np.zeros((num_rows,num_columns )), columns=list(set(no_spaces_unique_classes)))\n",
    "df[\"word\"]=lines\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37075e-f08b-4666-8bec-2a6db2893929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b508190e-52cc-454c-b395-8b954254497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 51877/51877 [00:22<00:00, 2320.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Use tqdm to add a progress bar\n",
    "for i in tqdm(range(num_rows), desc=\"Processing rows\"):\n",
    "    feat = feats[i].split(\"|\")\n",
    "    feat=[j.replace(\" \", \"\").upper() for j in feat]\n",
    "    for j in range(num_columns):\n",
    "        if feat_classes[j] in feat:\n",
    "            df.loc[i, feat_classes[j]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255cc62c-7b48-472f-a289-61c729cc9b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hhhhhhllkkk']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hhhhhhllkkk'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e763d4b-bf61-4eec-b40e-36ffab1114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_character_list=[]\n",
    "for word in df[\"word\"] :\n",
    "    vocab_character_list +=[char for char in word]\n",
    "vocab_character=list(set(vocab_character_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbaca942-bfc1-4112-9ce1-759e2fb79a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bf71553-7eb6-4584-baf6-03f6ef02335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_char_wise_word_embedding(word: str, vocab_character, embed_size: int = 256, kernel_size: int = 3):\n",
    "    \n",
    "    char_to_idx_map = {char: idx for idx, char in enumerate(vocab_character)}\n",
    "    ohe_characters = np.eye(len(vocab_character))\n",
    "\n",
    "    max_length = len(word)\n",
    "\n",
    "    idx_representation = [char_to_idx_map[char] for char in word]\n",
    "    ohe_representation = ohe_characters[idx_representation].T\n",
    "    padded_ohe_representation = np.pad(ohe_representation, ((0, 0), (0, max_length - len(word))))\n",
    "    ohe_word = np.expand_dims(padded_ohe_representation, axis=0)\n",
    "\n",
    "    # Initializing the layers\n",
    "    convolution_layer = tf.keras.layers.Conv1D(filters=embed_size, kernel_size=kernel_size, use_bias=False)\n",
    "    activation_layer = tf.keras.layers.Activation('tanh')\n",
    "    global_pooling_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "    fully_connected_layer = tf.keras.layers.Dense(embed_size, activation='tanh')\n",
    "\n",
    "    conv_out = convolution_layer(ohe_word)\n",
    "    activation_out = activation_layer(conv_out)\n",
    "    global_pool_out = global_pooling_layer(activation_out)\n",
    "    fully_connected_out = fully_connected_layer(tf.expand_dims(global_pool_out, axis=0))\n",
    "\n",
    "    # Reshape to (256, 1)\n",
    "    embedding = tf.squeeze(fully_connected_out)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38345913-109c-44a4-906d-0ffa4b582943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0011865106644108891,\n",
       " 0.0022239703685045242,\n",
       " 0.0035275095142424107,\n",
       " 0.0027712257578969,\n",
       " -0.0033746198751032352,\n",
       " -0.0016713471850380301,\n",
       " -0.003558840835466981,\n",
       " 0.0025828250218182802,\n",
       " 0.00053779425797984,\n",
       " 0.0021194524597376585,\n",
       " 0.0013767980271950364,\n",
       " -0.0009722941322252154,\n",
       " -0.0017511246260255575,\n",
       " 0.002690819324925542,\n",
       " -0.0017262628534808755,\n",
       " -0.005453997291624546,\n",
       " 0.0031577537301927805,\n",
       " -0.0013332392554730177,\n",
       " -0.0013630035100504756,\n",
       " 0.0005468390882015228,\n",
       " 0.0030410089530050755,\n",
       " 0.0005997002008371055,\n",
       " 0.0009108752710744739,\n",
       " -0.005919233430176973,\n",
       " -0.0029530709143728018,\n",
       " -0.00484000938013196,\n",
       " -0.0019387700594961643,\n",
       " -2.1885796741116792e-05,\n",
       " -0.00252588652074337,\n",
       " -0.001842707279138267,\n",
       " -0.006107002031058073,\n",
       " 0.007570923771709204,\n",
       " -9.543487249175087e-05,\n",
       " -0.001251579262316227,\n",
       " -0.002920981962233782,\n",
       " -0.003214753232896328,\n",
       " 0.0005371744045987725,\n",
       " -0.0024976416025310755,\n",
       " 0.0018336668144911528,\n",
       " 0.0023759210016578436,\n",
       " -0.0044279457069933414,\n",
       " -0.0028948786202818155,\n",
       " 0.001052416511811316,\n",
       " -0.0017464060802012682,\n",
       " -0.0058758617378771305,\n",
       " 0.004091846756637096,\n",
       " -0.0011950910557061434,\n",
       " -0.00030198521562851965,\n",
       " -0.004265193361788988,\n",
       " 0.0010244515724480152,\n",
       " 0.0004119295335840434,\n",
       " -0.007549135945737362,\n",
       " 0.000679094169754535,\n",
       " 0.0008002962567843497,\n",
       " -0.0013822815380990505,\n",
       " -0.0016454377910122275,\n",
       " -0.0002907708694692701,\n",
       " 0.0032997196540236473,\n",
       " 0.0014902477851137519,\n",
       " -0.0008342748624272645,\n",
       " -0.005175680387765169,\n",
       " -0.0025296418461948633,\n",
       " -0.0005626563797704875,\n",
       " 0.00027211548876948655,\n",
       " 0.003578266128897667,\n",
       " 0.0026643164455890656,\n",
       " -0.002605283632874489,\n",
       " -0.0007187861483544111,\n",
       " -0.00519590824842453,\n",
       " -0.0038373046554625034,\n",
       " -0.002777857007458806,\n",
       " 0.002514501567929983,\n",
       " 0.0016207876615226269,\n",
       " 7.891371205914766e-05,\n",
       " -0.0005064475699327886,\n",
       " 0.0011836928315460682,\n",
       " 0.0036431646440178156,\n",
       " 0.005404511000961065,\n",
       " 0.0025723776780068874,\n",
       " -0.0027290191501379013,\n",
       " -0.0004431762208696455,\n",
       " 0.002618611790239811,\n",
       " 0.00243252981454134,\n",
       " 0.0001611690386198461,\n",
       " 0.002017712453380227,\n",
       " 0.004180287476629019,\n",
       " -0.0024205276276916265,\n",
       " -0.005182264372706413,\n",
       " 0.0029284085612744093,\n",
       " -0.003435451304540038,\n",
       " -0.002935462398454547,\n",
       " 0.0050099920481443405,\n",
       " -0.0009121160255745053,\n",
       " -0.0009694957407191396,\n",
       " -0.0005082975840196013,\n",
       " 0.004107260145246983,\n",
       " 0.0011357399635016918,\n",
       " -0.00020261101599317044,\n",
       " -0.0016443384811282158,\n",
       " 0.0011072010966017842]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_char_wise_word_embedding(\"cette\",vocab_character, embed_size=100, kernel_size=5).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "654a6f1b-b258-4107-bb38-335993541c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 51877/51877 [11:59<00:00, 72.15it/s] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[feat_classes]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# MultiLabelBinarizer for multi-label encoding\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mlb \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelBinarizer\u001b[49m()\n\u001b[0;32m      9\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for word in tqdm(df[\"word\"], desc=\"Processing rows\"):\n",
    "    X.append(get_char_wise_word_embedding(word,vocab_character, embed_size=100, kernel_size=5).numpy().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b790e759-ea93-49a9-9788-a35d59bc1788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_padded) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb9dcef9-4e9c-4c4a-9156-88ab3d1b4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1038/1038 [==============================] - 130s 122ms/step - loss: 0.1606 - accuracy: 0.3755 - val_loss: 0.1533 - val_accuracy: 0.3792\n",
      "Epoch 2/50\n",
      "1038/1038 [==============================] - 129s 124ms/step - loss: 0.1545 - accuracy: 0.3801 - val_loss: 0.1534 - val_accuracy: 0.3792\n",
      "Epoch 3/50\n",
      "1038/1038 [==============================] - 130s 125ms/step - loss: 0.1543 - accuracy: 0.3801 - val_loss: 0.1529 - val_accuracy: 0.3792\n",
      "Epoch 4/50\n",
      "1038/1038 [==============================] - 128s 124ms/step - loss: 0.1539 - accuracy: 0.3801 - val_loss: 0.1485 - val_accuracy: 0.3792\n",
      "Epoch 5/50\n",
      "1038/1038 [==============================] - 123s 118ms/step - loss: 0.1462 - accuracy: 0.3692 - val_loss: 0.1400 - val_accuracy: 0.3792\n",
      "Epoch 6/50\n",
      "1038/1038 [==============================] - 121s 117ms/step - loss: 0.1422 - accuracy: 0.3661 - val_loss: 0.1393 - val_accuracy: 0.3792\n",
      "Epoch 7/50\n",
      "1038/1038 [==============================] - 342s 330ms/step - loss: 0.1451 - accuracy: 0.3623 - val_loss: 0.1430 - val_accuracy: 0.3408\n",
      "Epoch 10/50\n",
      "1038/1038 [==============================] - 131s 127ms/step - loss: 0.1422 - accuracy: 0.3636 - val_loss: 0.1389 - val_accuracy: 0.3783\n",
      "Epoch 11/50\n",
      "1038/1038 [==============================] - 132s 127ms/step - loss: 0.1403 - accuracy: 0.3610 - val_loss: 0.1375 - val_accuracy: 0.3792\n",
      "Epoch 12/50\n",
      "1038/1038 [==============================] - 124s 120ms/step - loss: 0.1394 - accuracy: 0.3588 - val_loss: 0.1378 - val_accuracy: 0.3797\n",
      "Epoch 13/50\n",
      " 724/1038 [===================>..........] - ETA: 37s - loss: 0.1385 - accuracy: 0.3627"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\medsam\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "y = df[feat_classes]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming X is padded sequences and y is your target labels\n",
    "# Modify the input shape based on your actual sequence length\n",
    "sequence_length = X_train.shape[1]\n",
    "\n",
    "# Build a deep learning model with a Bidirectional LSTM layer\n",
    "model = Sequential()\n",
    "\n",
    "# Add an Embedding layer if your input is not already embedded\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length))\n",
    "\n",
    "# Add a Bidirectional LSTM layer\n",
    "model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True), input_shape=(sequence_length, 1)))\n",
    "\n",
    "# Flatten the output if needed\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))  # Use 'sigmoid' for multi-label classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy[1]:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
